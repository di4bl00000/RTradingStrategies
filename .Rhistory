## Set the AR parameters
ar1 <- 0.6
ar2 <- 0.2
ma1 <- -0.2
sigma <- sqrt(0.2)
## Sample from an ARMA(2, 1) process
a <- arima.sim(model = list(ar = c(ar1, ar2), ma = ma1), n = n,
innov = rnorm(n) * sigma)
## Create a state space representation out of the four ARMA parameters
arma21ss <- function(ar1, ar2, ma1, sigma) {
Tt <- matrix(c(ar1, ar2, 1, 0), ncol = 2)
Zt <- matrix(c(1, 0), ncol = 2)
ct <- matrix(0)
dt <- matrix(0, nrow = 2)
GGt <- matrix(0)
H <- matrix(c(1, ma1), nrow = 2) * sigma
HHt <- H %*% t(H)
a0 <- c(0, 0)
P0 <- matrix(1e6, nrow = 2, ncol = 2)
return(list(a0 = a0, P0 = P0, ct = ct, dt = dt, Zt = Zt, Tt = Tt, GGt = GGt,
HHt = HHt))
}
## The objective function passed to 'optim'
objective <- function(theta, yt) {
sp <- arma21ss(theta["ar1"], theta["ar2"], theta["ma1"], theta["sigma"])
ans <- fkf(a0 = sp$a0, P0 = sp$P0, dt = sp$dt, ct = sp$ct, Tt = sp$Tt,
Zt = sp$Zt, HHt = sp$HHt, GGt = sp$GGt, yt = yt)
return(-ans$logLik)
}
theta <- c(ar = c(0, 0), ma1 = 0, sigma = 1)
fit <- optim(theta, objective, yt = rbind(a), hessian = TRUE)
fit
## Confidence intervals
rbind(fit$par - qnorm(0.975) * sqrt(diag(solve(fit$hessian))),
fit$par + qnorm(0.975) * sqrt(diag(solve(fit$hessian))))
## Filter the series with estimated parameter values
sp <- arma21ss(fit$par["ar1"], fit$par["ar2"], fit$par["ma1"], fit$par["sigma"])
ans <- fkf(a0 = sp$a0, P0 = sp$P0, dt = sp$dt, ct = sp$ct, Tt = sp$Tt,
Zt = sp$Zt, HHt = sp$HHt, GGt = sp$GGt, yt = rbind(a))
## Compare the prediction with the realization
plot(ans, at.idx = 1, att.idx = NA, CI = NA)
lines(a, lty = "dotted")
## Compare the filtered series with the realization
plot(ans, at.idx = NA, att.idx = 1, CI = NA)
lines(a, lty = "dotted")
## Check whether the residuals are Gaussian
plot(ans, type = "resid.qq")
## Check for linear serial dependence through 'acf'
plot(ans, type = "acf")
## <--------------------------------------------------------------------------->
## Example 2: Local level model for the Nile's annual flow.
## <--------------------------------------------------------------------------->
## Transition equation:
## alpha[t+1] = alpha[t] + eta[t], eta[t] ~ N(0, HHt)
## Measurement equation:
## y[t] = alpha[t] + eps[t], eps[t] ~  N(0, GGt)
y <- Nile
y[c(3, 10)] <- NA  # NA values can be handled
## Set constant parameters:
dt <- ct <- matrix(0)
Zt <- Tt <- matrix(1)
a0 <- y[1]            # Estimation of the first year flow
P0 <- matrix(100)     # Variance of 'a0'
## Estimate parameters:
fit.fkf <- optim(c(HHt = var(y, na.rm = TRUE) * .5,
GGt = var(y, na.rm = TRUE) * .5),
fn = function(par, ...)
-fkf(HHt = matrix(par[1]), GGt = matrix(par[2]), ...)$logLik,
yt = rbind(y), a0 = a0, P0 = P0, dt = dt, ct = ct,
Zt = Zt, Tt = Tt, check.input = FALSE)
## Filter Nile data with estimated parameters:
fkf.obj <- fkf(a0, P0, dt, ct, Tt, Zt, HHt = matrix(fit.fkf$par[1]),
GGt = matrix(fit.fkf$par[2]), yt = rbind(y))
## Compare with the stats' structural time series implementation:
fit.stats <- StructTS(y, type = "level")
fit.fkf$par
fit.stats$coef
## Plot the flow data together with fitted local levels:
plot(y, main = "Nile flow")
lines(fitted(fit.stats), col = "green")
lines(ts(fkf.obj$att[1, ], start = start(y), frequency = frequency(y)), col = "blue")
legend("top", c("Nile flow data", "Local level (StructTS)", "Local level (fkf)"),
col = c("black", "green", "blue"), lty = 1)
load("~/workspace/RTradingStrategies/IF1202.rda")
fix(IF1202)
head(IF1202)
write.csv(IF1202, file="IF1202.csv")
write.zoo(IF1202, file="IF1202.csv", sep=",")
demo(gas)
demo(vandrivers)
demo(mumps)
ssm
data(vandrivers)
vandrivers
vandrivers$y <- ts(vandrivers$y,start=1969,frequency=12)
vandrivers
vandrivers$y
vd.time <- time(vandrivers$y)
vd.time
vd <- ssm( y ~ tvar(1) + seatbelt + sumseason(vd.time,12),
family=poisson(link="log"),
data=vandrivers,
phi = c(1,0.0004),
C0=diag(13)*100,
fit=FALSE
)
vd
phi(vd)["(Intercept)"] <- exp(- 2*3.703307 )
C0(vd) <- diag(13)*1000
vd.res <- kfs(vd)
vd.res
plot( vd.res$m[,1:3] )
plot(y,ylim=c(0,20))
attach(vandrivers)
plot(y,ylim=c(0,20))
lines(exp(vd.res$m[,1]+vd.res$m[,2]*seatbelt),lwd=2 )
SS
data(kurit)  ## West & Harrison, page 40
m1 <- SS(y=kurit,
Fmat=function(tt,x,phi) return(matrix(1)),
Gmat=function(tt,x,phi) return(matrix(1)),
Wmat=function(tt,x,phi) return(matrix(5)), ## Alternatively Wmat=matrix(5)
Vmat=function(tt,x,phi) return(matrix(100)), ## Alternatively Vmat=matrix(100)
m0=matrix(130),C0=matrix(400)
)
plot(m1$y)
plot(m1$y)
m1.f <- kfilter(m1)
m1.s <- smoother(m1.f)
lines(m1.f$m,lty=2,col=2)
lines(m1.s$m,lty=2,col=2)
m2 <- m1
Wmat(m2) <- function(tt,x,phi) {
if (tt==10) return(matrix(900))
else return(matrix(5))
}
m2.f <- kfilter(m2)
m2.s <- smoother(m2.f)
lines(m2.f$m,lty=2,col=4)
lines(m2.s$m,lty=2,col=4)
phi.start <- StructTS(log10(UKgas),type="BSM")$coef[c(4,1,2,3)]
gasmodel <- ssm( log10(UKgas) ~ -1+
tvar(polytime(time,1))+
tvar(sumseason(time,12)),
phi=phi.start)
m0(gasmodel)
C0(gasmodel)
phi(gasmodel)
fit <- getFit(gasmodel)
plot( fit$m[,1:3]  )
y<-Nile
modelNile<-structSSM(y=y)
fit<-fitSSM(inits=c(0.5*log(var(Nile)),0.5*log(var(Nile))),model=modelNile)
# Filtering and state smoothing
kfsNile<-KFS(fit$model,smoothing="state")
# Simple plot of series and the smoothed signal = Z*alphahat
plot(kfsNile,col=1:2)
# Confidence intervals for the state
lows<-c(kfsNile$alphahat-qnorm(0.95)*sqrt(c(kfsNile$V)))
ups<-c(kfsNile$alphahat+qnorm(0.95)*sqrt(c(kfsNile$V)))
plot.ts(cbind(y,c(kfsNile$alphahat),lows,ups), plot.type="single", col=c(1:2,3,3),
ylab="Predicted Annual flow", main="River Nile")
# Missing obse
y<-Nile
y[c(21:40,61:80)]<-NA
modelNile<-structSSM(y=y,H=fit$model$H,Q.level=fit$model$Q)
kfsNile<-KFS(modelNile,smoothing="state")
# Filtered state
plot.ts(cbind(y,c(NA,kfsNile$a[,-c(1,101)])), plot.type="single", col=c(1:2,3,3),
ylab="Predicted Annual flow", main="River Nile")
#  Smoothed state
plot.ts(cbind(y,c(kfsNile$alp)), plot.type="single", col=c(1:2,3,3),
ylab="Predicted Annual flow", main="River Nile")
# Prediction of missing observations
predictNile<-predict(kfsNile)
lows<-predictNile$y-qnorm(0.95)*sqrt(c(predictNile$F))
ups<-predictNile$y+qnorm(0.95)*sqrt(c(predictNile$F))
plot.ts(cbind(y,predictNile$y,lows,ups), plot.type="single", col=c(1:2,4,4),
ylab="Predicted Annual flow", main="River Nile")
data(GlobalTemp)
modelTemp<-SSModel(y=GlobalTemp, Z = matrix(1,nrow=2), T=1, R=1, H=matrix(NA,2,2),
Q=NA, a1=0, P1=0, P1inf=1)
fit<-fitSSM(inits=c(0.5*log(.1),0.5*log(.1),0.5*log(.1),0),model=modelTemp)
outTemp<-KFS(fit$model,smooth="both")
ts.plot(cbind(modelTemp$y,t(outTemp$alphahat)),col=1:3)
legend("bottomright",legend=c(colnames(GlobalTemp), "Smoothed signal"), col=1:3, lty=1)
# Example of multivariate series where first series follows stationary ARMA(1,1)
# process and second stationary AR(1) process.
y1<-arima.sim(model=list(ar=0.8,ma=0.3), n=100, sd=0.5)
model1<-arimaSSM(y=y1,arima=list(ar=0.8,ma=0.3),Q=0.5^2)
y2<-arima.sim(model=list(ar=-0.5), n=100)
model2<-arimaSSM(y=y2,arima=list(ar=-0.5))
model<-model1+model2
# Another way:
modelb<-arimaSSM(y=ts.union(y1,y2),arima=list(list(ar=0.8,ma=0.3),list(ar=-0.5)),Q=diag(c(0.5^2,1)))
f.out<-KFS(model)
model<-structSSM(y=log(Seatbelts[,"drivers"]),trend="level",seasonal="time",
X=cbind(log(Seatbelts[,"kms"]),log(Seatbelts[,"PetrolPrice"]),Seatbelts[,c("law")]))
fit<-fitSSM(inits=rep(-1,3),model=model)
out<-KFS(fit$model,smoothing="state")
plot(out,lty=1:2,col=1:2,main="Observations and smoothed signal with and without seasonal component")
lines(signal(out,states=c(1,13:15))$s,col=4,lty=1)
legend("bottomleft",legend=c("Observations", "Smoothed signal","Smoothed level"), col=c(1,2,4), lty=c(1,2,1))
# Multivariate model with constant seasonal pattern in frequency domain
model<-structSSM(y=log(Seatbelts[,c("front","rear")]),trend="level",seasonal="freq",
X=cbind(log(Seatbelts[,c("kms")]),log(Seatbelts[,"PetrolPrice"]),Seatbelts[,"law"]),
H=NA,Q.level=NA,Q.seasonal=0)
sbFit<-fitSSM(inits=rep(-1,6),model=model)
out<-KFS(sbFit$model,smoothing="state")
ts.plot(signal(out,states=c(1:2,25:30))$s,model$y,col=1:4)
# Poisson model
model<-structSSM(y=Seatbelts[,"VanKilled"],trend="level",seasonal="time",X=Seatbelts[,"law"],
distribution="Poisson")
# Estimate variance parameters
fit<-fitSSM(inits=rep(0.5*log(0.005),2), model=model)
model<-fit$model
# Approximating model, gives also the conditional mode of theta
amod<-approxSSM(model)
out.amod<-KFS(amod,smoothing="state")
# State smoothing via importance sampling
out<-KFS(model,nsim=1000)
# Observations with exp(smoothed signal) computed by
# importance sampling in KFS, and by approximating model
ts.plot(cbind(model$y,out$yhat,exp(amod$theta)),col=1:3) # Almost identical
# It is more interesting to look at the smoothed values of exp(level + intervention)
lev1<-exp(signal(out,states=c(1,13))$s)
lev2<-exp(signal(out.amod,states=c(1,13))$s)
# These are slightly biased as E[exp(x)] > exp(E[x]), better to use importance sampling:
vansample<-importanceSSM(model,save.model=FALSE,nsim=250)
# nsim is number of independent samples, as default two antithetic variables are used,
# so total number of samples is 1000.
w<-vansample$weights/sum(vansample$weights)
level<-colSums(t(exp(vansample$states[1,,]+model$Z[1,13,]*vansample$states[13,,]))*w)
ts.plot(cbind(model$y,lev1,lev2,level),col=1:4) #' Almost identical results
# Confidence intervals (no seasonal component)
varlevel<-colSums(t(exp(vansample$states[1,,]+model$Z[1,13,]*vansample$states[13,,])^2)*w)-level^2
intv<-level + qnorm(0.975)*varlevel%o%c(-1,1)
ts.plot(cbind(model$y,level,intv),col=c(1,2,3,3))
# Simulation error
# Mean estimation error of the single draw with 2 antithetics
level2<-t(exp(vansample$states[1,,1:250]+model$Z[1,13,]*vansample$states[13,,1:250])-level)*w[1:250]+
t(exp(vansample$states[1,,251:500]+model$Z[1,13,]*vansample$states[13,,251:500])-level)*w[251:500]+
t(exp(vansample$states[1,,501:750]+model$Z[1,13,]*vansample$states[13,,501:750])-level)*w[501:750]+
t(exp(vansample$states[1,,751:1000]+model$Z[1,13,]*vansample$states[13,,751:1000])-level)*w[751:1000]
varsim<-colSums(level2^2)
ts.plot(sqrt(varsim/varlevel)*100)
# Same without antithetic variables
vansamplenat<-importanceSSM(model,save.model=FALSE,nsim=1000,antithetics=FALSE)
w<-vansamplenat$weights/sum(vansamplenat$weights)
levelnat<-colSums(t(exp(vansamplenat$states[1,,]+
model$Z[1,13,]*vansamplenat$states[13,,]))*w)
varsimnat<-colSums((t(exp(vansamplenat$states[1,,]+
model$Z[1,13,]*vansamplenat$states[13,,])-levelnat)*w)^2)
varlevelnat<-colSums(t(exp(vansamplenat$states[1,,]+
model$Z[1,13,]*vansamplenat$states[13,,])^2)*w)-levelnat^2
ts.plot(sqrt(varsimnat/varlevelnat)*100)
ts.plot((sqrt(varsimnat)-sqrt(varsim))/sqrt(varsimnat)*100)
SSModel
regSSM
getSymbols("600000.SS")
head(600000.SS)
head("600000.SS")
head(`600000.SS`)
`600000.SS`
head("600000.SS")
head(`600000.SS`)
adjustOHLC(`600000.SS`)
head(`600000.SS`)
tail(`600000.SS`)
getSplits(`600000.SS`)
getSymbols("MSFT")
getSplits("MSFT")
getSplits
getEarnings(`600000.SS`)
install.packages("XML")
getEarnings(`600000.SS`)
install.packages("XML")
getEarnings(`600000.SS`)
getFinancials('JAVA')
getFinancials('JAVA')
getFin('AAPL')
detach("package:qmao")
library("qmao")
detach("package:qmao")
library("qmao")
getFin('AAPL')
ssm
SS
m1 <- SS( Fmat = function(tt, x, phi) {
Fmat      <- matrix(NA, nrow=3, ncol=1)
Fmat[1,1] <- 1
Fmat[2,1] <- cos(2*pi*tt/12)
Fmat[3,1] <- sin(2*pi*tt/12)
return(Fmat)
},
Gmat = function(tt, x, phi) {
matrix(c(1,0,0,0,1,0,0,0,1), nrow=3)
},
Wmat = matrix(c(0.01,0,0,0,0.1,0,0,0,0.1), nrow=3),
Vmat = matrix(1),
m0   = matrix(c(0,0,0), nrow=1),
C0   = matrix(c(1,0,0,0,0.001,0,0,0,0.001), nrow=3, ncol=3)
)
## Simulates 100 observation from m1
m1 <- recursion(m1, 100)
m1
W[1,2:3] <- 0
W[2:3,1] <- 0
W[2,2]   <- (W[2,2]+W[3,3])/2
W[3,3]   <- W[2,2]
W[2,3]   <- 0
W[3,2]   <- 0
W
m1 <- SS( Fmat = function(tt, x, phi) {
Fmat      <- matrix(NA, nrow=3, ncol=1)
Fmat[1,1] <- 1
Fmat[2,1] <- cos(2*pi*tt/12)
Fmat[3,1] <- sin(2*pi*tt/12)
return(Fmat)
},
Gmat = function(tt, x, phi) {
matrix(c(1,0,0,0,1,0,0,0,1), nrow=3)
},
Wmat = matrix(c(0.01,0,0,0,0.1,0,0,0,0.1), nrow=3),
Vmat = matrix(1),
m0   = matrix(c(0,0,0), nrow=1),
C0   = matrix(c(1,0,0,0,0.001,0,0,0,0.001), nrow=3, ncol=3)
)
## Simulates 100 observation from m1
m1 <- recursion(m1, 100)
m1
Wstruc <- function(W){
W[1,2:3] <- 0
W[2:3,1] <- 0
W[2,2]   <- (W[2,2]+W[3,3])/2
W[3,3]   <- W[2,2]
W[2,3]   <- 0
W[3,2]   <- 0
return(W)
}
## Estimstes variances and covariances of W by use of the EM algorithm
estimates <- EMalgo(m1, Wstruc=Wstruc)
estimates$ss$Wmat
estimates
names(estimates)
names(estimates$ss)
estimates
estimates$ss$Wmat
plot(estimates$ss)
class(estimates$ss)
plot.SS
data(mumps)
mumps
head(mumps)
class(mumps)
head(mumps)
times(mumps)
time(mumps)
index <- 1:length(mumps) # use 'index' instead of time
index
model <- ssm( mumps ~ -1 + tvar(polytime(index,1)),
family=poisson(link=log))
model
results <- getFit(model)
getFit
ssm$ss
results <- getFit(model)
plot(mumps,type='l',ylab='Number of Cases',xlab='',axes=FALSE)
lines( exp(results$m[,1]), lwd=2)
results2 <- extended(model$ss)
results3 <- kfs(model) ## yields the same
data(kurit)
m1 <- SS(kurit)
phi(m1) <- c(100,5)
m0(m1) <- matrix(130)
C0(m1) <- matrix(400)
m1.f <- kfilter(m1)
plot(m1$y)
lines(m1.f$m,lty=2)
m1 <- SS( Fmat = function(tt, x, phi) {
Fmat      <- matrix(NA, nrow=3, ncol=1)
Fmat[1,1] <- 1
Fmat[2,1] <- cos(2*pi*tt/12)
Fmat[3,1] <- sin(2*pi*tt/12)
return(Fmat)
},
Gmat = function(tt, x, phi) {
matrix(c(1,0,0,0,1,0,0,0,1), nrow=3)
},
Wmat = function(tt, x, phi) {
matrix(c(0.01,0,0,0,0.1,0,0,0,0.1), nrow=3)},
Vmat = function(tt, x, phi) {matrix(1)},
m0   = matrix(c(0,0,0), nrow=1),
C0   = matrix(c(1,0,0,0,0.001,0,0,0,0.001), nrow=3, ncol=3)
)
m1 <- recursion(m1, 100)
ssm1 <- ssm(m1$y ~ -1 + tvar(polytime(1:m1$n),1)
+ tvar(polytrig(1:m1$n, 1)),
family="gaussian", fit=FALSE)
smoothed <- Fkfs(ssm1$ss, tvar=c(m1$n, 1, 1, 1))
phi.start <- StructTS(log10(UKgas),type="BSM")$coef[c(4,1,2,3)]
gasmodel <- ssm( log10(UKgas) ~ -1+ tvar(polytime(time,1))+
tvar(sumseason(time,4)), phi=phi.start, fit=FALSE)
smoothed <- Fkfs(gasmodel$ss,tvar=c(1,1,1,1))
## Trend plot
## Trend plot
ts.plot( smoothed$kfas$alphahat[1,] )
## Season plot
ts.plot( smoothed$kfas$alphahat[3,] )
polytrig(1:10,degree=2)
season(1:12,period=4)
demo()
f <- array(c(.5,.3,.2,.4),c(2,2))
h <- array(c(1,0,0,1),c(2,2))
k <- array(c(.5,.3,.2,.4),c(2,2))
ss <- SS(F=f,G=NULL,H=h,K=k)
is.SS(ss)
ss
detach("package:dse")
library("dse")
f <- array(c(.5,.3,.2,.4),c(2,2))
h <- array(c(1,0,0,1),c(2,2))
k <- array(c(.5,.3,.2,.4),c(2,2))
ss <- SS(F=f,G=NULL,H=h,K=k)
is.SS(ss)
ss
ss <- SS(F=f,G=NULL,H=h,K=k)
ss
detach("package:stats")
detach("package:stats")
## see also JohnsonJohnson, Nile and AirPassengers
require(graphics)
trees <- window(treering, start=0)
(fit <- StructTS(trees, type = "level"))
plot(trees)
lines(fitted(fit), col = "green")
tsdiag(fit)
(fit <- StructTS(log10(UKgas), type = "BSM"))
par(mfrow = c(4, 1))
plot(log10(UKgas))
plot(cbind(fitted(fit), resids=resid(fit)), main = "UK gas consumption")
## keep some parameters fixed; trace optimizer:
StructTS(log10(UKgas), type = "BSM", fixed = c(0.1,0.001,NA,NA),
optim.control = list(trace=TRUE))
install.packages("cts")
install.packages("timsac")
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
W
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/kalman.R')
source('~/workspace/RTradingStrategies/dma_adx.R')
testPackList$eachRun
source('~/workspace/RTradingStrategies/dma_adx.R')
source('~/workspace/RTradingStrategies/dma_adx.R')
source('~/workspace/RTradingStrategies/dma_adx.R')
source('~/workspace/RTradingStrategies/dma_adx.R')
source('~/workspace/RTradingStrategies/dma_adx.R')
source('~/workspace/RTradingStrategies/dma_adx.R')
source('~/workspace/RTradingStrategies/myMA.R')
source('~/workspace/RTradingStrategies/myMA.R')
demo(macd)
source('~/workspace/RTradingStrategies/myMA.R')
source('~/workspace/RTradingStrategies/myMA.R')
source('~/workspace/RTradingStrategies/myMA.R')
source('~/workspace/RTradingStrategies/myMA.R')
source('~/workspace/RTradingStrategies/myMA.R')
source('~/workspace/RTradingStrategies/dma_adx.R')
library("TSdbi")
library("tframe")
ts(rnorm(100), start=c(1982,1), frequency=12)
ts(1:10, frequency = 4, start = c(1959, 2)) # 2nd Quarter of 1959
print( ts(1:10, frequency = 7, start = c(12, 2)), calendar = TRUE)
z <- tframe(ts(rnorm(100), start=c(1982,1), frequency=12))
z
is.tframe(z)
matrix(rnorm(200), 100,2)
zz <- tframed(matrix(rnorm(200), 100,2), tf=z)
zz
is.tframed(zz)
zzz <- tframed(matrix(rnorm(200), 100,2), tf=zz)
zzz
as.tframe(start=c(1992,1), end=c(1996,3), frequency=4)
Tobs(as.tframe(start=c(1992,1), end=c(1996,3), frequency=4))
end(as.tframe(start=c(1992,1), end=c(1996,3), frequency=4))
z <- tframed(rnorm(100), start=c(1982,1), frequency=12)
z
z <- ts(rnorm(100), start=c(1982,1), frequency=12)
tfstart(z)
z <- tframed(matrix(rnorm(200), 100,2),
tf=list(start=c(1982,1), frequency=12))
z
tfend(z)
Tobs(z)
time(z)
tfprint(ts(rnorm(100)))
trimNA(ts(rbind(NA, matrix(1:20,10,2)), start=c(1980,1), frequency=12))
library("RTAQ")
data("sample_tdataraw")
sample_tdataraw
head(sample_tdataraw)
data("sample_qdataraw")
head(sample_qdataraw)
